What is Recursion?

In simple terms, Recursion is when a function calls itself to solve a smaller version of the same problem.

Imagine you are standing in a long line at a cinema. You want to know what "number" you are in the line.

    You ask the person in front of you: "What number are you?"

    They don't know either! So they ask the person in front of them.

    This keeps happening until the message reaches the very first person in line.

    That first person knows they are #1. They tell the second person, "I am #1."

    The second person now knows they are #2, and tells the third person... and finally, the information reaches you.

That is recursion. You solved a big problem (your position) by breaking it into a smaller version of the same problem (the position of the person in front).

2. The Three Pillars of a Recursive Function

To write any recursive code in C++, you must satisfy these three things. If you miss even one, your code will fail.
I. The Base Case (The "Stop" Button)

This is the most important part. It tells the function when to stop calling itself. Without a base case, the function will call itself forever until your computer runs out of memory (this is called Stack Overflow).

    In our line example: The base case was the person at the very front who knew they were #1.

II. The Recursive Relation (The "Step")

This is the part where the function calls itself, but with a smaller input.

    If you are solving for n, the recursive call should be for n−1 or n/2, etc.

III. The Processing (The "Work")

This is any extra logic you do (like adding numbers or printing a value) before or after the recursive call.

Let's Look at Code: The Factorial Example

The factorial of a number n (written as n!) is the product of all positive integers less than or equal to n.
5!=5×4×3×2×1=120

Notice something? 5! is actually 5×(4!). And 4! is 4×(3!). The general formula is:
f(n)=n×f(n−1)

int factorial(int n) {
    // 1. Base Case
    if (n == 0 || n == 1) {
        return 1;
    }

    // 2. Recursive Relation & Processing
    return n * factorial(n - 1);
}
4. How the "Call Stack" Works (The Brain of Recursion)

This is the "secret sauce" that makes you a master. When a function calls itself, the computer doesn't just jump; it saves the current state of the function in a place called the Stack.

When you call factorial(3):

    factorial(3) starts. It needs factorial(2) to finish. It pauses and waits.

    factorial(2) starts. It needs factorial(1) to finish. It pauses and waits.

    factorial(1) starts. Base Case hit! It returns 1.

    Now, the stack "unwinds." factorial(2) gets the 1, multiplies it by 2, and returns 2.

    Finally, factorial(3) gets the 2, multiplies it by 3, and returns 6.

Crucial Lesson: Recursion has two phases:

    The Descent (Going down): Calling the functions and filling the stack.

    The Ascent (Coming back): Returning the values and clearing the stack.

Why use Recursion?

You might ask, "Why not just use a for loop?" While loops are often faster, recursion is essential for:

    Complex Data Structures: Trees and Graphs are naturally recursive.

    Divide and Conquer: Algorithms like Merge Sort and Quick Sort.

    Backtracking: Solving puzzles like Sudoku or the N-Queens problem.

Fibonacci numbers are a series of numbers starting with 0 and 1, where each subsequent number is the sum of the two preceding ones, forming the sequence: 0, 1, 1, 2, 3, 5, 8, 13, and so on, appearing frequently in nature, art, and computer science. The rule is defined as \(F_{n}=F_{n-1}+F_{n-2}\), with \(F_{0}=0\) and \(F_{1}=1\). 

int fib(int n) {
    // Base Cases
    if (n == 0) return 0;
    if (n == 1) return 1;

    // Recursive Relation
    return fib(n - 1) + fib(n - 2);
}

2. Visualizing the Recursion Tree

When you call fib(4), it doesn't calculate everything at once. It branches out like a tree. This is the Recursion Tree.
Step-by-Step Execution:

    fib(4) calls fib(3) (Left branch).

    fib(3) waits and calls fib(2) (Left branch).

    fib(2) waits and calls fib(1).

    fib(1) hits a Base Case! It returns 1.

    Now fib(2) calls its right branch, fib(0).

    fib(0) hits a Base Case! It returns 0.

    fib(2) now has both values: 1+0=1. It returns 1 up to fib(3).

    fib(3) now calls its right branch, fib(1), which returns 1.

    fib(3) now has both: 1+1=2. It returns 2 up to fib(4).

    Finally, fib(4) calls its right branch... and the process continues until the whole tree is resolved!

The "Master" Insight: The Cost of Recursion

Look closely at the tree. Do you notice something "wasteful"?

    We calculated fib(2) multiple times.

    We calculated fib(1) multiple times.

This is called Redundant Work.

    Teacher's Note: In simple recursion, the Fibonacci tree grows exponentially. For n=40, your computer might take a few seconds. For n=100, it might take years! This is why we later learn Dynamic Programming (Memoization) to "remember" these values.

. Head Recursion vs. Tail Recursion

This is a high-level concept often asked in interviews.
Type	Definition	Example
Tail Recursion	The recursive call is the last thing the function does.	Printing numbers n to 1.
Head Recursion	The recursive call is at the beginning; work is done after the call.	Printing numbers 1 to n.

Why does this matter? In Tail Recursion, the computer can optimize the memory (Stack) because it doesn't need to "come back" and do more work. It just moves forward.


Note: so as we know that the recurssion is bad as it do repeated task again and again so due to this reason we use dynamic programming(DP) to solve this problem.

. The Core Philosophy of DP

In the world of elite programming, we follow a simple rule: "Those who do not remember the past are condemned to repeat it."

If I ask you "What is 1+1+1+1+1?", you count and say "5." If I then add another "+1" and ask for the total, you don't start from zero; you just say "6" because you remembered the previous result. That is DP.

To use DP, a problem must have two things:

    Overlapping Subproblems: You are solving the same thing over and over (like fib(2) in our tree).

    Optimal Substructure: The final answer can be built from answers to smaller versions of the problem.

The Two Methods of DP

There are two ways to "remember" things. Every elite student must know both.
Method A: Memoization (The "Top-Down" Approach)

This is just Recursion + a Notebook. Before the function calculates anything, it checks its "notebook" (an array or map).

    If the answer is in the notebook, return it immediately.

    If not, calculate it, write it in the notebook, and then return it.

int memo[100]; // Our "Notebook", initialized with -1

int fib(int n) {
    if (n <= 1) return n;

    // Step 1: Check the notebook
    if (memo[n] != -1) return memo[n];

    // Step 2: Calculate and STORE the result in the notebook
    memo[n] = fib(n - 1) + fib(n - 2);
    
    return memo[n];
}

Method B: Tabulation (The "Bottom-Up" Approach)

This method throws away recursion entirely and uses a Loop. It’s called "Bottom-Up" because you start from the smallest base cases (0 and 1) and build your way up to n.

int fib(int n) {
    if (n <= 1) return n;
    
    int dp[n + 1]; // Our table
    dp[0] = 0;
    dp[1] = 1;

    for (int i = 2; i <= n; i++) {
        dp[i] = dp[i - 1] + dp[i - 2];
    }

    return dp[n];
}
Feature	Memoization (Top-Down)	Tabulation (Bottom-Up)
Logic	Easier to write (starts from n).	Harder to think (starts from 0).
State	Uses Recursion (Stack memory).	Uses Loops (No stack overhead).
Efficiency	Can be slightly slower due to function calls.	Generally faster and more memory-efficient.
Space	O(N) for Stack + O(N) for Array.	O(N) for Array only.

The Final Level: Space Optimization

An "average" student stops at Tabulation. An "Elite" student realizes that to find dp[i], we only need the previous two values (dp[i−1] and dp[i−2]). We don't need the whole array!

int fib(int n) {
    int prev2 = 0, prev1 = 1;
    for (int i = 2; i <= n; i++) {
        int current = prev1 + prev2;
        prev2 = prev1;
        prev1 = current;
    }
    return prev1;
}
Time Complexity: O(N)

Space Complexity: O(1) (Constant space! No arrays, no recursion).

What is the Tower of Hanoi?
Imagine three rods: Source (A), Helper (B), and Destination (C). On Rod A, there are n disks of different sizes, stacked in decreasing order (biggest on the bottom, smallest on top).

The Goal: Move all disks from Rod A to Rod C. The Rules:

    Only one disk can be moved at a time.

    A disk can only be placed on an empty rod or on top of a larger disk.

    You can never put a larger disk on top of a smaller one.
The "Elite" Strategy: Recursive Thinking

If I ask you to move 1 disk, it's easy: A → C. If I ask you to move 64 disks, your brain might explode. But a Master thinks like this:

"To move n disks from A to C using B as a helper:"

    Step 1: Move the top (n−1) disks from A to B (using C as a helper).

    Step 2: Move the remaining 1 biggest disk directly from A to C.

    Step 3: Move those (n−1) disks from B to C (using A as a helper).

Wait, read that again. To solve for n, we solve for n−1, then do 1 bit of work, then solve for n−1 again. This is pure recursion!
void towerOfHanoi(int n, char source, char helper, char destination) {
    // Base Case: If only 1 disk, just move it!
    if (n == 1) {
        cout << "Move disk 1 from " << source << " to " << destination << endl;
        return;
    }

    // Step 1: Move n-1 disks from Source to Helper
    towerOfHanoi(n - 1, source, destination, helper);

    // Step 2: Move the nth (biggest) disk from Source to Destination
    cout << "Move disk " << n << " from " << source << " to " << destination << endl;

    // Step 3: Move the n-1 disks from Helper to Destination
    towerOfHanoi(n - 1, helper, source, destination);
}

The Time Complexity (The Cost of Perfection)

For every n disks, the number of moves required is 2n−1.

    3 disks = 7 moves.

    10 disks = 1,023 moves.

    64 disks = 18,446,744,073,709,551,615 moves.

    Fun Fact: There is a legend that monks are solving this with 64 golden disks. When they finish, the world will end. Luckily, at one move per second, it will take them 584 billion years!
The Recursion Tree

For Tower of Hanoi, the tree is perfectly symmetrical. Each call splits into two more calls until it hits the base case.

What is Backtracking? (The "Undo" Button)
Imagine you are in a massive maze. You reach a fork in the road: Left or Right?

    You go Left.

    After 10 steps, you hit a Dead End.

    What do you do? You don't just give up and stay there. You go back to the fork and try going Right.

Backtracking is a refined form of recursion. It explores all possible paths, but the moment it realizes a path cannot lead to a solution, it backtracks (erases its last step) and tries the next possibility.
